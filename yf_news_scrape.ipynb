{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page(url):\n",
    "    \"\"\"Download a webpage and return a beautiful soup doc\"\"\"\n",
    "    ##### Web scrapper for infinite scrolling page #####\n",
    "    driver = webdriver.Chrome(executable_path=r\"E:\\Chromedriver\\chromedriver_win32_chrome83\\chromedriver.exe\")\n",
    "    driver.get(url)\n",
    "    time.sleep(2)  # Allow 2 seconds for the web page to open\n",
    "    scroll_pause_time = 1 # You can set your own pause time. My laptop is a bit slow so I use 1 sec\n",
    "    screen_height = driver.execute_script(\"return window.screen.height;\")   # get the screen height of the web\n",
    "    i = 1\n",
    "\n",
    "    while True:\n",
    "        # scroll one screen height each time\n",
    "        driver.execute_script(\"window.scrollTo(0, {screen_height}*{i});\".format(screen_height=screen_height, i=i))  \n",
    "        i += 1\n",
    "        time.sleep(scroll_pause_time)\n",
    "        # update scroll height each time after scrolled, as the scroll height can change after we scrolled the page\n",
    "        scroll_height = driver.execute_script(\"return document.body.scrollHeight;\")  \n",
    "        # Break the loop when the height we need to scroll to is larger than the total scroll height\n",
    "        if i == 10:\n",
    "            break \n",
    "\n",
    "    ##### Extract Reddit URLs #####\n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_news_tags(doc):\n",
    "    \"\"\"Get the list of tags containing news information\"\"\"\n",
    "    news_class = \"Ov(h) Pend(44px) Pstart(25px)\" ## class name of div tag \n",
    "    news_list  = doc.find_all('div', {'class': news_class})\n",
    "    return news_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_news(news_tag):\n",
    "    \"\"\"Get the news data point and return dictionary\"\"\"\n",
    "    news_source = news_tag.find_all('span')[0].text #source\n",
    "    news_time = news_tag.find_all('span')[1].text #link\n",
    "    news_headline = news_tag.find('a').text #heading\n",
    "    news_content = news_tag.find('p').text #content\n",
    "    news_image = news_tag.findParent().find('img')['src'] #thumb image\n",
    "    return { 'source' : news_source,\n",
    "            'time' : news_time,    \n",
    "            'headline' : news_headline,\n",
    "            'content' : news_content,\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_yahoo_news(url, path=None):\n",
    "    \"\"\"Get the yahoo finance market news and write them to CSV file \"\"\"\n",
    "    if path is None:\n",
    "        path = 'stock-market-news.csv'\n",
    "        \n",
    "    print('Requesting html page')\n",
    "    doc = get_page(url)\n",
    "\n",
    "    print('Extracting news tags')\n",
    "    news_list = get_news_tags(doc)\n",
    "\n",
    "    print('Parsing news tags')\n",
    "    news_data = [parse_news(news_tag) for news_tag in news_list]\n",
    "\n",
    "    print('Save the data to a CSV')\n",
    "    news_df = pd.DataFrame(news_data)\n",
    "    news_df.to_csv(path, index=None)\n",
    "    \n",
    "    #This return statement is optional, we are doing this just analyze the final output \n",
    "    return news_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = 'https://finance.yahoo.com/topic/stock-market-news/'\n",
    "# doc = get_page(url)\n",
    "# news_list = get_news_tags(doc)\n",
    "# news_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entire Stock Market News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YAHOO_NEWS_URL = 'https://finance.yahoo.com/topic/stock-market-news/'\n",
    "news_df = scrape_yahoo_news(YAHOO_NEWS_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "\n",
    "pd.set_option('display.max_columns', None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_pipeline = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = [None] * len(news_df)\n",
    "sentiment_score = [None] * len(news_df)\n",
    "index = -1\n",
    "for sentence in news_df['headline']:\n",
    "    index+=1\n",
    "    result = sentiment_pipeline(sentence[:512])[0]\n",
    "    sentiment[index] = result['label']\n",
    "    sentiment_score[index] = result['score']\n",
    "news_df['Sentiment'] = sentiment\n",
    "news_df['Score'] = sentiment_score\n",
    "\n",
    "\n",
    "sentiment = [None] * len(news_df)\n",
    "sentiment_score = [None] * len(news_df)\n",
    "index = -1\n",
    "for sentence in news_df['content']:\n",
    "    index+=1\n",
    "    result = sentiment_pipeline(sentence[:512])[0]\n",
    "    sentiment[index] = result['label']\n",
    "    sentiment_score[index] = result['score']\n",
    "news_df['Sentiment2'] = sentiment\n",
    "news_df['Score2'] = sentiment_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(x = 'Sentiment', data = news_df[news_df['Score'] > 0.8], hue = 'Sentiment', hue_order=['POSITIVE', 'NEGATIVE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(x = 'Sentiment2', data = news_df[news_df['Score2'] > 0.8], hue = 'Sentiment2', hue_order=['POSITIVE', 'NEGATIVE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, 'C:/Users/Woon/Desktop/Columbia/Applied Analytics/Term3/Sentiment_SNP')\n",
    "\n",
    "import helper_functions\n",
    "from helper_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from plotly import tools\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the bar chart from 5 rated reviews ##\n",
    "freq_dict = defaultdict(int)\n",
    "for sent in news_df[\"headline\"]:\n",
    "    for word in generate_ngrams(sent,3):\n",
    "        freq_dict[word] += 1\n",
    "fd_sorted = pd.DataFrame(sorted(freq_dict.items(), key=lambda x: x[1])[::-1])\n",
    "fd_sorted.columns = [\"word\", \"wordcount\"]\n",
    "trace0 = horizontal_bar_chart(fd_sorted.head(10), 'green')\n",
    "\n",
    "# Creating two subplots\n",
    "fig = tools.make_subplots(rows=1, cols=1, vertical_spacing=0.04,\n",
    "                          subplot_titles=[\"Frequent words\"])\n",
    "fig.append_trace(trace0, 1, 1)\n",
    "#fig.append_trace(trace1, 1, 2)\n",
    "fig['layout'].update(height=600, width=600, paper_bgcolor='rgb(233,233,233)', title=\"Word Count Plots\")\n",
    "py.iplot(fig, filename='word-plots');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the bar chart from 5 rated reviews ##\n",
    "freq_dict = defaultdict(int)\n",
    "for sent in news_df[\"headline\"]:\n",
    "    for word in generate_ngrams(sent,2):\n",
    "        freq_dict[word] += 1\n",
    "fd_sorted = pd.DataFrame(sorted(freq_dict.items(), key=lambda x: x[1])[::-1])\n",
    "fd_sorted.columns = [\"word\", \"wordcount\"]\n",
    "trace0 = horizontal_bar_chart(fd_sorted.head(10), 'green')\n",
    "\n",
    "# Creating two subplots\n",
    "fig = tools.make_subplots(rows=1, cols=1, vertical_spacing=0.04,\n",
    "                          subplot_titles=[\"Frequent words\"])\n",
    "fig.append_trace(trace0, 1, 1)\n",
    "#fig.append_trace(trace1, 1, 2)\n",
    "fig['layout'].update(height=600, width=600, paper_bgcolor='rgb(233,233,233)', title=\"Word Count Plots\")\n",
    "py.iplot(fig, filename='word-plots');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the bar chart from 5 rated reviews ##\n",
    "freq_dict = defaultdict(int)\n",
    "for sent in news_df[\"content\"]:\n",
    "    for word in generate_ngrams(sent,4):\n",
    "        freq_dict[word] += 1\n",
    "fd_sorted = pd.DataFrame(sorted(freq_dict.items(), key=lambda x: x[1])[::-1])\n",
    "fd_sorted.columns = [\"word\", \"wordcount\"]\n",
    "trace0 = horizontal_bar_chart(fd_sorted.head(10), 'green')\n",
    "\n",
    "# Creating two subplots\n",
    "fig = tools.make_subplots(rows=1, cols=1, vertical_spacing=0.04,\n",
    "                          subplot_titles=[\"Frequent words\"])\n",
    "fig.append_trace(trace0, 1, 1)\n",
    "#fig.append_trace(trace1, 1, 2)\n",
    "fig['layout'].update(height=600, width=600, paper_bgcolor='rgb(233,233,233)', title=\"Word Count Plots\")\n",
    "py.iplot(fig, filename='word-plots');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the bar chart from 5 rated reviews ##\n",
    "freq_dict = defaultdict(int)\n",
    "for sent in news_df[\"content\"]:\n",
    "    for word in generate_ngrams(sent,3):\n",
    "        freq_dict[word] += 1\n",
    "fd_sorted = pd.DataFrame(sorted(freq_dict.items(), key=lambda x: x[1])[::-1])\n",
    "fd_sorted.columns = [\"word\", \"wordcount\"]\n",
    "trace0 = horizontal_bar_chart(fd_sorted.head(10), 'green')\n",
    "\n",
    "# Creating two subplots\n",
    "fig = tools.make_subplots(rows=1, cols=1, vertical_spacing=0.04,\n",
    "                          subplot_titles=[\"Frequent words\"])\n",
    "fig.append_trace(trace0, 1, 1)\n",
    "#fig.append_trace(trace1, 1, 2)\n",
    "fig['layout'].update(height=600, width=600, paper_bgcolor='rgb(233,233,233)', title=\"Word Count Plots\")\n",
    "py.iplot(fig, filename='word-plots');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the bar chart from 5 rated reviews ##\n",
    "freq_dict = defaultdict(int)\n",
    "for sent in news_df[\"content\"]:\n",
    "    for word in generate_ngrams(sent,2):\n",
    "        freq_dict[word] += 1\n",
    "fd_sorted = pd.DataFrame(sorted(freq_dict.items(), key=lambda x: x[1])[::-1])\n",
    "fd_sorted.columns = [\"word\", \"wordcount\"]\n",
    "trace0 = horizontal_bar_chart(fd_sorted.head(10), 'green')\n",
    "\n",
    "# Creating two subplots\n",
    "fig = tools.make_subplots(rows=1, cols=1, vertical_spacing=0.04,\n",
    "                          subplot_titles=[\"Frequent words\"])\n",
    "fig.append_trace(trace0, 1, 1)\n",
    "#fig.append_trace(trace1, 1, 2)\n",
    "fig['layout'].update(height=600, width=600, paper_bgcolor='rgb(233,233,233)', title=\"Word Count Plots\")\n",
    "py.iplot(fig, filename='word-plots');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPY Ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import Request, urlopen\n",
    "from urllib.error import HTTPError\n",
    "import socket\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://finviz.com/quote.ashx?t=SPY&ty=c&ta=1&p=d\"\n",
    "\n",
    "\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "cookies = {\"CONSENT\": \"YES+cb.20210720-07-p0.en+FX+410\"}\n",
    "\n",
    "req = Request(url, headers=headers)\n",
    "\n",
    "try:\n",
    "    contents = urlopen(req).read() \n",
    "    soup = BeautifulSoup(contents, features=\"html.parser\")\n",
    "\n",
    "    sentence2 = []\n",
    "\n",
    "    for tag in soup.find_all('a'):\n",
    "\n",
    "        sentence = tag.text.split(\".\")\n",
    "        sentence2.append(sentence)\n",
    "\n",
    "except urllib.error.HTTPError as err:\n",
    "    print(err.code)\n",
    "\n",
    "except socket.timeout as se:\n",
    "    print(\"socket timeout\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(sentence2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Headline'] = df[0]\n",
    "df['Sentiment'] = -2\n",
    "df = pd.DataFrame(list(zip(df['Headline'], df['Sentiment'])), columns=['Headline', 'Sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = []\n",
    "\n",
    "for string in df['Headline']:\n",
    "    i.append(count_words(string))\n",
    "\n",
    "df['word_count'] = i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = [None] * len(df)\n",
    "sentiment_score = [None] * len(df)\n",
    "index = -1\n",
    "for sentence in df['Headline']:\n",
    "    index+=1\n",
    "    result = sentiment_pipeline(sentence[:512])[0]\n",
    "    sentiment[index] = result['label']\n",
    "    sentiment_score[index] = result['score']\n",
    "df['Sentiment'] = sentiment\n",
    "df['Score'] = sentiment_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['word_count'] > 10]\n",
    "df['Headline_Lower'] = df['Headline'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(x = 'Sentiment', data = df[df['Score'] > 0.8], hue = 'Sentiment', hue_order=['POSITIVE', 'NEGATIVE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NUSI Ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://finviz.com/quote.ashx?t=NUSI&ty=c&ta=1&p=d\"\n",
    "\n",
    "\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "cookies = {\"CONSENT\": \"YES+cb.20210720-07-p0.en+FX+410\"}\n",
    "\n",
    "req = Request(url, headers=headers)\n",
    "\n",
    "try:\n",
    "    contents = urlopen(req).read() \n",
    "    soup = BeautifulSoup(contents, features=\"html.parser\")\n",
    "\n",
    "    sentence2 = []\n",
    "\n",
    "    for tag in soup.find_all('a'):\n",
    "\n",
    "        sentence = tag.text.split(\".\")\n",
    "        sentence2.append(sentence)\n",
    "\n",
    "except urllib.error.HTTPError as err:\n",
    "    print(err.code)\n",
    "\n",
    "except socket.timeout as se:\n",
    "    print(\"socket timeout\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(sentence2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Headline'] = df[0]\n",
    "df['Sentiment'] = -2\n",
    "df = pd.DataFrame(list(zip(df['Headline'], df['Sentiment'])), columns=['Headline', 'Sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = []\n",
    "\n",
    "for string in df['Headline']:\n",
    "    i.append(count_words(string))\n",
    "\n",
    "df['word_count'] = i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = [None] * len(df)\n",
    "sentiment_score = [None] * len(df)\n",
    "index = -1\n",
    "for sentence in df['Headline']:\n",
    "    index+=1\n",
    "    result = sentiment_pipeline(sentence[:512])[0]\n",
    "    sentiment[index] = result['label']\n",
    "    sentiment_score[index] = result['score']\n",
    "df['Sentiment'] = sentiment\n",
    "df['Score'] = sentiment_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['word_count'] > 10]\n",
    "df['Headline_Lower'] = df['Headline'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(x = 'Sentiment', data = df[df['Score'] > 0.8], hue = 'Sentiment', hue_order=['POSITIVE', 'NEGATIVE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XOM YF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YAHOO_NEWS_URL = 'https://finance.yahoo.com/quote/XOM/news?p=XOM'\n",
    "news_df = scrape_yahoo_news(YAHOO_NEWS_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "\n",
    "pd.set_option('display.max_columns', None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_pipeline = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = [None] * len(news_df)\n",
    "sentiment_score = [None] * len(news_df)\n",
    "index = -1\n",
    "for sentence in news_df['headline']:\n",
    "    index+=1\n",
    "    result = sentiment_pipeline(sentence[:512])[0]\n",
    "    sentiment[index] = result['label']\n",
    "    sentiment_score[index] = result['score']\n",
    "news_df['Sentiment'] = sentiment\n",
    "news_df['Score'] = sentiment_score\n",
    "\n",
    "\n",
    "sentiment = [None] * len(news_df)\n",
    "sentiment_score = [None] * len(news_df)\n",
    "index = -1\n",
    "for sentence in news_df['content']:\n",
    "    index+=1\n",
    "    result = sentiment_pipeline(sentence[:512])[0]\n",
    "    sentiment[index] = result['label']\n",
    "    sentiment_score[index] = result['score']\n",
    "news_df['Sentiment2'] = sentiment\n",
    "news_df['Score2'] = sentiment_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(x = 'Sentiment', data = news_df[news_df['Score'] > 0.8], hue = 'Sentiment', hue_order=['POSITIVE', 'NEGATIVE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(x = 'Sentiment2', data = news_df[news_df['Score2'] > 0.8], hue = 'Sentiment2', hue_order=['POSITIVE', 'NEGATIVE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XOM Ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://finviz.com/quote.ashx?t=XOM&p=d\"\n",
    "\n",
    "\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "cookies = {\"CONSENT\": \"YES+cb.20210720-07-p0.en+FX+410\"}\n",
    "\n",
    "req = Request(url, headers=headers)\n",
    "\n",
    "try:\n",
    "    contents = urlopen(req).read() \n",
    "    soup = BeautifulSoup(contents, features=\"html.parser\")\n",
    "\n",
    "    sentence2 = []\n",
    "\n",
    "    for tag in soup.find_all('a'):\n",
    "\n",
    "        sentence = tag.text.split(\".\")\n",
    "        sentence2.append(sentence)\n",
    "\n",
    "except urllib.error.HTTPError as err:\n",
    "    print(err.code)\n",
    "\n",
    "except socket.timeout as se:\n",
    "    print(\"socket timeout\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(sentence2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Headline'] = df[0]\n",
    "df['Sentiment'] = -2\n",
    "df = pd.DataFrame(list(zip(df['Headline'], df['Sentiment'])), columns=['Headline', 'Sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = []\n",
    "\n",
    "for string in df['Headline']:\n",
    "    i.append(count_words(string))\n",
    "\n",
    "df['word_count'] = i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = [None] * len(df)\n",
    "sentiment_score = [None] * len(df)\n",
    "index = -1\n",
    "for sentence in df['Headline']:\n",
    "    index+=1\n",
    "    result = sentiment_pipeline(sentence[:512])[0]\n",
    "    sentiment[index] = result['label']\n",
    "    sentiment_score[index] = result['score']\n",
    "df['Sentiment'] = sentiment\n",
    "df['Score'] = sentiment_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['word_count'] > 10]\n",
    "df['Headline_Lower'] = df['Headline'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(x = 'Sentiment', data = df[df['Score'] > 0.8], hue = 'Sentiment', hue_order=['POSITIVE', 'NEGATIVE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQQQ Ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://finviz.com/quote.ashx?t=SQQQ&ty=c&ta=1&p=d\"\n",
    "\n",
    "\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "cookies = {\"CONSENT\": \"YES+cb.20210720-07-p0.en+FX+410\"}\n",
    "\n",
    "req = Request(url, headers=headers)\n",
    "\n",
    "try:\n",
    "    contents = urlopen(req).read() \n",
    "    soup = BeautifulSoup(contents, features=\"html.parser\")\n",
    "\n",
    "    sentence2 = []\n",
    "\n",
    "    for tag in soup.find_all('a'):\n",
    "\n",
    "        sentence = tag.text.split(\".\")\n",
    "        sentence2.append(sentence)\n",
    "\n",
    "except urllib.error.HTTPError as err:\n",
    "    print(err.code)\n",
    "\n",
    "except socket.timeout as se:\n",
    "    print(\"socket timeout\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(sentence2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Headline'] = df[0]\n",
    "df['Sentiment'] = -2\n",
    "df = pd.DataFrame(list(zip(df['Headline'], df['Sentiment'])), columns=['Headline', 'Sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = []\n",
    "\n",
    "for string in df['Headline']:\n",
    "    i.append(count_words(string))\n",
    "\n",
    "df['word_count'] = i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = [None] * len(df)\n",
    "sentiment_score = [None] * len(df)\n",
    "index = -1\n",
    "for sentence in df['Headline']:\n",
    "    index+=1\n",
    "    result = sentiment_pipeline(sentence[:512])[0]\n",
    "    sentiment[index] = result['label']\n",
    "    sentiment_score[index] = result['score']\n",
    "df['Sentiment'] = sentiment\n",
    "df['Score'] = sentiment_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['word_count'] > 10]\n",
    "df['Headline_Lower'] = df['Headline'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(x = 'Sentiment', data = df[df['Score'] > 0.8], hue = 'Sentiment', hue_order=['POSITIVE', 'NEGATIVE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T.TO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YAHOO_NEWS_URL = 'https://finance.yahoo.com/quote/T.TO/news?p=T.TO'\n",
    "news_df = scrape_yahoo_news(YAHOO_NEWS_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "\n",
    "pd.set_option('display.max_columns', None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_pipeline = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = [None] * len(news_df)\n",
    "sentiment_score = [None] * len(news_df)\n",
    "index = -1\n",
    "for sentence in news_df['headline']:\n",
    "    index+=1\n",
    "    result = sentiment_pipeline(sentence[:512])[0]\n",
    "    sentiment[index] = result['label']\n",
    "    sentiment_score[index] = result['score']\n",
    "news_df['Sentiment'] = sentiment\n",
    "news_df['Score'] = sentiment_score\n",
    "\n",
    "\n",
    "sentiment = [None] * len(news_df)\n",
    "sentiment_score = [None] * len(news_df)\n",
    "index = -1\n",
    "for sentence in news_df['content']:\n",
    "    index+=1\n",
    "    result = sentiment_pipeline(sentence[:512])[0]\n",
    "    sentiment[index] = result['label']\n",
    "    sentiment_score[index] = result['score']\n",
    "news_df['Sentiment2'] = sentiment\n",
    "news_df['Score2'] = sentiment_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(x = 'Sentiment', data = news_df[news_df['Score'] > 0.8], hue = 'Sentiment', hue_order=['POSITIVE', 'NEGATIVE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(x = 'Sentiment2', data = news_df[news_df['Score2'] > 0.8], hue = 'Sentiment2', hue_order=['POSITIVE', 'NEGATIVE'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "998c911629ba937bcf1bf80465453e12e8c5c2c818cb936f93ef7cf495a937a9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
